{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# following along with https://elitedatascience.com/keras-tutorial-deep-learning-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing numpy and setting a seed for reproductibility\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing standart keras modules/layers/utilities\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load image data form MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181bf4c250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUP8Pt/ALPExulGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1816e9d290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# ^ show stuff inline\n",
    "plt.imshow(X_train[0], cmap=plt.cm.binary) #\"cmap=plt.cm.binary\" used to make image b/w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Preprocess input data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# old shape (currently # of samples, height, width)\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explicitly declaring the depth dimension\n",
    "# need shape to look like # of samples, depth, height, width\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# new shape\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert data type\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize values\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# taking a look at the shape of our class label data\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expecting 10 classes (one for each digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# looking at labels for first 10 training samples\n",
    "print y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess class labels\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# resulting shape\n",
    "print Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using a pre-defined / proven architecture for this\n",
    "# declare sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minhgeneralassembly/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", data_format=\"channels_first\", input_shape=(1, 28, 28...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# declare CNN input layer\n",
    "# added dim_ordering='th' since i'm using tensorflow and it has different ways of ordering dimensions\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), dim_ordering='th'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more layers to model\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 229s 4ms/step - loss: 0.2676 - acc: 0.9180\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 227s 4ms/step - loss: 0.1089 - acc: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182e93f590>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, \n",
    "          batch_size=32, nb_epoch=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## note to self: try to get test/train metrics on the above. -mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.047756706222263162, 0.98580000000000001]\n"
     ]
    }
   ],
   "source": [
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.047756706222263162, 0.98580000000000001]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: Unshape image to look at, then predict on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = X_test[777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182df033d0>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182de71ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view test_image (undoing the transformation on a copy)\n",
    "test_image_in = test_image\n",
    "test_image_in *= 255\n",
    "test_image_in = test_image_in.reshape(28, 28)\n",
    "plt.imshow(test_image_in, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict on thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_image[np.newaxis, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_image[np.newaxis, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
